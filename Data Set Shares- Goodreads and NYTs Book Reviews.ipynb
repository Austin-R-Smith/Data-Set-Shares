{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7da16b1d",
   "metadata": {},
   "source": [
    "## Data Set Shares: Reviews of Popular Books\n",
    "\n",
    "This notebook includes the code that scrapes two data sets related to the most popular books, as deteremined by the Goodreads community. \n",
    "\n",
    "The first dataset includes the top 100 best books of all time, as reviewed by the Goodreads community. Community reviews for each of the top 100 books are included as text data. That text data also includes a synopsis and extraneous information from the Goodreads website.  \n",
    "\n",
    "The second dataset includes the NYT's reviews for any of those 100 books that have been reviewed by the NYT.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84a0da4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "from bs4.element import Comment\n",
    "import re\n",
    "from nyt_api import api_key\n",
    "import pandas as pd\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15a1a469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract visible text (will need this later)\n",
    "\n",
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a724b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to turn a URL into a nice file name (will need this later)\n",
    "\n",
    "def generate_filename_from_url(url) :\n",
    "    \n",
    "    if not url :\n",
    "        return None\n",
    "    \n",
    "    # drop the http or https\n",
    "    name = url.replace(\"https\",\"\").replace(\"http\",\"\")\n",
    "\n",
    "    # Replace useless chareacters with UNDERSCORE\n",
    "    name = name.replace(\"://\",\"\").replace(\".\",\"_\").replace(\"/\",\"_\")\n",
    "    \n",
    "    # remove last underscore\n",
    "    last_underscore_spot = name.rfind(\"_\")\n",
    "    \n",
    "    name = name[:last_underscore_spot] + name[(last_underscore_spot+1):]\n",
    "\n",
    "    # tack on .txt\n",
    "    name = name + \".txt\"\n",
    "    \n",
    "    return(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf516287",
   "metadata": {},
   "source": [
    "### Part 1: Goodreads Best Books List - Review Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "181f1991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect information on the first 100 books, which are stored on the first page of the best books list\n",
    "site = [\"https://www.goodreads.com/list/show/1.Best_Books_Ever\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f443a722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.goodreads.com/list/show/1.Best_Books_Ever']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the link\n",
    "print(site)\n",
    "r = requests.get(site[0])\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8904369",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1c2b481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grabs all of the book titles\n",
    "\n",
    "book_titles = []\n",
    "\n",
    "for title in soup.find_all('a', class_ = 'bookTitle'):\n",
    "    book_titles.append(title.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1585233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/book/show/2767052-the-hunger-games',\n",
       " '/book/show/2.Harry_Potter_and_the_Order_of_the_Phoenix',\n",
       " '/book/show/2657.To_Kill_a_Mockingbird',\n",
       " '/book/show/1885.Pride_and_Prejudice',\n",
       " '/book/show/41865.Twilight',\n",
       " '/book/show/19063.The_Book_Thief',\n",
       " '/book/show/170448.Animal_Farm',\n",
       " '/book/show/11127.The_Chronicles_of_Narnia',\n",
       " '/book/show/30.J_R_R_Tolkien_4_Book_Boxed_Set',\n",
       " '/book/show/11870085-the-fault-in-our-stars']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note that each of these urls starts with the prefix: https://www.goodreads.com/\n",
    "# so I need to add that to them so the function below works\n",
    "book_titles[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0d3c41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_book_titles = []\n",
    "\n",
    "for item in book_titles :\n",
    "    full_book_titles.append(''.join('https://www.goodreads.com/'+item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7aed4e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.goodreads.com//book/show/2767052-the-hunger-games',\n",
       " 'https://www.goodreads.com//book/show/2.Harry_Potter_and_the_Order_of_the_Phoenix',\n",
       " 'https://www.goodreads.com//book/show/2657.To_Kill_a_Mockingbird',\n",
       " 'https://www.goodreads.com//book/show/1885.Pride_and_Prejudice',\n",
       " 'https://www.goodreads.com//book/show/41865.Twilight',\n",
       " 'https://www.goodreads.com//book/show/19063.The_Book_Thief',\n",
       " 'https://www.goodreads.com//book/show/170448.Animal_Farm',\n",
       " 'https://www.goodreads.com//book/show/11127.The_Chronicles_of_Narnia',\n",
       " 'https://www.goodreads.com//book/show/30.J_R_R_Tolkien_4_Book_Boxed_Set',\n",
       " 'https://www.goodreads.com//book/show/11870085-the-fault-in-our-stars']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_book_titles[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4175d93f",
   "metadata": {},
   "source": [
    "Now we can crawl through each of the book title pages to extract the text and store it in a dictionary.\n",
    "\n",
    "URL will be the key and text will be the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6d0f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to hold results\n",
    "titles_text = dict()\n",
    "\n",
    "for link in full_book_titles :\n",
    "    try :\n",
    "        r = requests.get(link)\n",
    "    except :\n",
    "        pass \n",
    "    \n",
    "    if r.status_code == 200 :\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        texts = soup.findAll(text=True)\n",
    "        visible_texts = filter(tag_visible, texts)\n",
    "        titles_text[link] = \" \".join(t.strip() for t in visible_texts)\n",
    "    else :\n",
    "        print(f\"We got code {r.status_code} for this link: {link}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96bb080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the text values for each book key is massive\n",
    "# check a portion of results for one book to make sure it worked\n",
    "\n",
    "titles_text['https://www.goodreads.com//book/show/2767052-the-hunger-games'][50000:51000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9d9d03",
   "metadata": {},
   "source": [
    "We now have a dictionary item where the keys are the URLs for each of the first 100 books and the values are all of the text on the synopsis/review pages of those books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a279536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write all text to files \n",
    "\n",
    "for item in titles_text :\n",
    "    output_file = generate_filename_from_url(item)\n",
    "\n",
    "    with open(output_file,'w',encoding = \"UTF-8\") as outfile :\n",
    "        outfile.write(\"\\t\".join([\"link\",\"text\"]) + \"\\n\")\n",
    "        \n",
    "        the_text = titles_text[item]\n",
    "\n",
    "        # get rid of some of our more annoying output chars\n",
    "        the_text = the_text.replace(\"\\t\",\" \").replace(\"\\n\",\" \").replace(\"\\r\",\" \") \n",
    "\n",
    "        if the_text : # test to see if it is non-empty\n",
    "            outfile.write(\"\\t\".join([item,the_text]) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf6c3bd",
   "metadata": {},
   "source": [
    "### Part 2: NYT's Book Reviews "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc022484",
   "metadata": {},
   "source": [
    "This scraping exercise will pull the NYT's book review for any book on Goodread's top 100 that has been reviewed by the NYT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10221359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/book/show/2767052-the-hunger-games',\n",
       " '/book/show/2.Harry_Potter_and_the_Order_of_the_Phoenix',\n",
       " '/book/show/2657.To_Kill_a_Mockingbird',\n",
       " '/book/show/1885.Pride_and_Prejudice',\n",
       " '/book/show/41865.Twilight',\n",
       " '/book/show/19063.The_Book_Thief',\n",
       " '/book/show/170448.Animal_Farm',\n",
       " '/book/show/11127.The_Chronicles_of_Narnia',\n",
       " '/book/show/30.J_R_R_Tolkien_4_Book_Boxed_Set',\n",
       " '/book/show/11870085-the-fault-in-our-stars']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have the list of top 100 titles from above\n",
    "book_titles[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5217ed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to pull from the NYT's API, I need the titles in a specific format -- \n",
    "# spaces: %20\n",
    "# apostrophes: %27\n",
    "# it looks like the titles start after either a \".\" or a \"-\". \n",
    "# I can take off 'book/show' for all the titles as a start\n",
    "\n",
    "titles = []\n",
    "\n",
    "for item in book_titles :\n",
    "    if \"/\" in item :\n",
    "        titles.append(item.split(\"/\"))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e4ba02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull off all but the title names (and some junk that I'll remove later)\n",
    "\n",
    "clean_titles = []\n",
    "\n",
    "for item in titles:\n",
    "    clean_titles.append(item[-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17c388c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then remove all the numbers, except for 1984 because that's a book title\n",
    "\n",
    "clean_titles_2 = []\n",
    "\n",
    "for item in clean_titles :\n",
    "    if '1984' not in item:\n",
    "        clean_titles_2.append(''.join([i for i in item if not i.isdigit()]))\n",
    "    else :\n",
    "        clean_titles_2.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02ad1e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if an s is preceded by an _, I need to replace it with \"%27\". \n",
    "\n",
    "titles_apostrophes = []\n",
    "\n",
    "for item in clean_titles_2 :\n",
    "    if '_s_' in item :\n",
    "        titles_apostrophes.append(item.replace('_s','%27s'))\n",
    "    else :\n",
    "        titles_apostrophes.append(item)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0797a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all of the spaces between words need to be coded as \"%20\"\n",
    "# some spaces are currently underscores\n",
    "\n",
    "titles_spaces = []\n",
    "\n",
    "for item in titles_apostrophes :\n",
    "    if '_' in item:\n",
    "        titles_spaces.append(item.replace('_','%20'))\n",
    "    else :\n",
    "        titles_spaces.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f55ee2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other spaces are curently dashes\n",
    "\n",
    "titles_spaces2 = []\n",
    "\n",
    "for item in titles_spaces :\n",
    "    if '-' in item:\n",
    "        titles_spaces2.append(item.replace('-','%20'))\n",
    "    else:\n",
    "        titles_spaces2.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e38197d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I fix 1984 manually \n",
    "\n",
    "odd_title_clean = []\n",
    "\n",
    "for item in titles_spaces2 :\n",
    "    if item == '40961427%201984' :\n",
    "        odd_title_clean.append(item.replace(\"40961427%201984\",\".1984\"))\n",
    "    else:\n",
    "        odd_title_clean.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c171dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the first character\n",
    "\n",
    "remove_first = []\n",
    "\n",
    "for item in odd_title_clean:\n",
    "    remove_first.append(item[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "342c7b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, if the title now starts with '2', delete those two characters\n",
    "\n",
    "nyt_titles = []\n",
    "\n",
    "for item in remove_first :\n",
    "    if item[0] == '2' :\n",
    "        nyt_titles.append(item[2:])\n",
    "    else :\n",
    "        nyt_titles.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a864b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the%20hunger%20games',\n",
       " 'Harry%20Potter%20and%20the%20Order%20of%20the%20Phoenix',\n",
       " 'To%20Kill%20a%20Mockingbird',\n",
       " 'Pride%20and%20Prejudice',\n",
       " 'Twilight',\n",
       " 'The%20Book%20Thief',\n",
       " 'Animal%20Farm',\n",
       " 'The%20Chronicles%20of%20Narnia',\n",
       " 'J%20R%20R%20Tolkien%20%20Book%20Boxed%20Set',\n",
       " 'the%20fault%20in%20our%20stars']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyt_titles[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222e1534",
   "metadata": {},
   "source": [
    "I now have 100 book titles in the form that the NYT's book review API can understand. I can iterate through every one of those titles and pull the review. If one exists, the results will include a URL that links to the review. If no NYT review exists for the book, it will return an empty space in the URL results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aedb5e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull results from NYT's reviews, wait 6 seconds between requests to avoid quote limit\n",
    "\n",
    "review_urls = defaultdict(list) \n",
    "\n",
    "for idx, title in enumerate(nyt_titles) :\n",
    "    \n",
    "    requestURL = ''.join('https://api.nytimes.com/svc/books/v3/reviews.json?title='+\n",
    "                       title + '&api-key='+ api_key)\n",
    "\n",
    "    requestHeaders = {\n",
    "        \"Accept\": \"applications/json\"\n",
    "    }\n",
    "\n",
    "    request = requests.get(requestURL, headers=requestHeaders)\n",
    "    \n",
    "    for review_obj in request.json()['results'] :\n",
    "        this_url = review_obj['url']\n",
    "        \n",
    "        if r'/movies/' in this_url : # make sure movie reviews aren't included\n",
    "            pass\n",
    "        else :\n",
    "            review_urls[title].append(this_url)  \n",
    "    \n",
    "    sleep(6)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a7f6626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crawl each page and extract the text into a dictionary\n",
    "# it put the text into a dictionary with the key as the book title and the value\n",
    "# as the text of the review\n",
    "\n",
    "site_text = dict()\n",
    "\n",
    "for key, values in review_urls.items() :\n",
    "    for link in values :\n",
    "    \n",
    "        try :\n",
    "            r = requests.get(link)\n",
    "        except :\n",
    "            pass \n",
    "    \n",
    "        if r.status_code == 200 :\n",
    "            soup = BeautifulSoup(r.text, 'html.parser')\n",
    "            texts = soup.findAll(text=True)\n",
    "            visible_texts = filter(tag_visible, texts) \n",
    "            site_text[key] = []\n",
    "            site_text[key].append(\" \".join(t.strip() for t in visible_texts))\n",
    "        else :\n",
    "            print(f\"We got code {r.status_code} for this link: {link}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a7215bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write text to a file \n",
    "\n",
    "for key, values in site_text.items() :\n",
    "    for value in values :\n",
    "        output_file = key\n",
    "        with open(output_file,'w',encoding = \"UTF-8\") as outfile :\n",
    "\n",
    "            the_text = value\n",
    "\n",
    "            # get rid of some of our more annoying output chars\n",
    "            the_text = the_text.replace(\"\\t\",\" \").replace(\"\\n\",\" \").replace(\"\\r\",\" \") \n",
    "\n",
    "            if the_text : # test to see if it is non-empty\n",
    "                outfile.write(\"\\t\".join([the_text]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed81a4f",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a437636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR USE IN ACQUIRE AND ANALYZE NOTEBOOK\n",
    "# Grabbing the titles of the books from Goodreads that have been reviewed by the NYT\n",
    "\n",
    "nyt_goodreads_books = []\n",
    "\n",
    "for key, value in review_urls.items() :\n",
    "    nyt_goodreads_books.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "48006eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['To%20Kill%20a%20Mockingbird',\n",
       " 'Twilight',\n",
       " 'The%20Book%20Thief',\n",
       " 'the%20fault%20in%20our%20stars',\n",
       " 'The%20Da%20Vinci%20Code',\n",
       " 'Memoirs%20of%20a%20Geisha',\n",
       " 'divergent',\n",
       " 'Crime%20and%20Punishment',\n",
       " 'The%20Little%20Prince',\n",
       " 'City%20of%20Bones',\n",
       " 'the%20help',\n",
       " 'Brave%20New%20World',\n",
       " 'A%20Thousand%20Splendid%20Suns',\n",
       " 'the%20lovely%20bones',\n",
       " 'The%20Odyssey',\n",
       " 'Life%20of%20Pi',\n",
       " 'Water%20for%20Elephants',\n",
       " 'The%20Handmaid%27s%20Tale',\n",
       " 'dune',\n",
       " 'Little%20Women',\n",
       " 'Harry%20Potter%20and%20the%20Deathly%20Hallows',\n",
       " 'The%20Stand',\n",
       " 'anna%20karenina',\n",
       " 'The%20Girl%20with%20the%20Dragon%20Tattoo',\n",
       " 'My%20Sister%27s%20Keeper',\n",
       " 'the%20color%20purple',\n",
       " 'The%20Road',\n",
       " 'Angela%27s%20Ashes',\n",
       " 'Don%20Quixote',\n",
       " 'the%20notebook',\n",
       " 'A%20Prayer%20for%20Owen%20Meany',\n",
       " 31,\n",
       " 30]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyt_goodreads_books"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
